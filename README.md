# E-Commerce Funnel Optimization Study

## Overview

This project analyzes customer behavior through an e-commerce purchase funnel using the **Online Retail (UCI)** dataset. The goal is to identify **where customers drop off**, **which customers drive revenue**, and **which products contribute most to sales**, then translate those findings into **actionable recommendations**.

## Business Questions

1. Where are the biggest drop-off points in the customer journey (first-time → repeat → high-value)?
2. What share of customers become engaged (2+ orders) and repeat (2+ months)?
3. Which customer segments (UK vs International) differ in value and repeat behavior?
4. Which RFM segments (Champions, Loyal, At Risk, etc.) drive revenue?
5. Which products contribute the most revenue, and how concentrated is that revenue?

## Dataset

**Source:** UCI Machine Learning Repository — Online Retail Dataset

* **Records:** ~541,909 transactions (raw)
* **Time Period:** 2010–2011
* **Columns:** InvoiceNo, StockCode, Description, Quantity, InvoiceDate, UnitPrice, CustomerID, Country
* **Link:** [https://archive.ics.uci.edu/ml/datasets/online+retail](https://archive.ics.uci.edu/ml/datasets/online+retail)

> Note: The raw Excel file is **not included** in this repo (see `.gitignore`). Place it locally in `data/raw/`.

## Tech Stack

* Python (pandas, numpy)
* matplotlib (visuals)
* Jupyter Notebooks
* openpyxl (Excel loading)

## Project Structure

```
ecommerce-funnel-analysis/
├── data/
│   ├── raw/                      # (local) Online Retail.xlsx (ignored)
│   └── processed/                # Outputs generated by notebooks
│       ├── cleaned_purchases.csv
│       ├── returns.csv
│       ├── rfm_analysis.csv
│       ├── customer_metrics.csv
│       └── product_performance.csv
├── notebooks/
│   ├── 01_data_exploration.ipynb
│   ├── 02_data_cleaning.ipynb
│   ├── 03_funnel_analysis.ipynb
│   └── 04_final_report.ipynb
├── requirements.txt
├── .gitignore
└── README.md
```

## How to Run

### 1) Install dependencies

```bash
pip install -r requirements.txt
```

### 2) Download the dataset

* Download `Online Retail.xlsx` from UCI (link above)
* Place it here:

```
data/raw/Online Retail.xlsx
```

### 3) Run notebooks in order

**Run order matters** because later notebooks depend on outputs from earlier ones:

1. `notebooks/01_data_exploration.ipynb`
2. `notebooks/02_data_cleaning.ipynb` → produces `cleaned_purchases.csv`, `returns.csv`
3. `notebooks/03_funnel_analysis.ipynb` → produces:

   * `rfm_analysis.csv`
   * `customer_metrics.csv`
   * `product_performance.csv`
4. `notebooks/04_final_report.ipynb` → loads the exported CSVs and presents final insights

## Key Results (from your run)

### Data Cleaning Summary

* Raw transactions: **541,909**
* Missing CustomerID removed: **135,080 (~24.9%)**
* Returns separated: **8,905 (~2.0%)**
* Additional outliers/bad rows removed: **5,805**
* Clean transactions saved: **392,119**

## Outputs

After running the pipeline, you will have:

* `data/processed/cleaned_purchases.csv`
* `data/processed/returns.csv`
* `data/processed/rfm_analysis.csv`
* `data/processed/customer_metrics.csv`
* `data/processed/product_performance.csv`

## Notes

* This is a learning + portfolio project built to be **reproducible** and **presentation-ready**.
* The final report notebook (`04_final_report.ipynb`) intentionally loads precomputed outputs to stay fast and stable.

## Contact

**Hiruy Kassa**
- Email: hiruygirmak@gmail.com
- LinkedIn: [linkedin.com/in/hiruykassa](https://linkedin.com/in/hiruykassa)
- GitHub: [github.com/hiruykassa](https://github.com/hiruykassa)

* Email: [hiruygirmak@gmail.com](mailto:hiruygirmak@gmail.com)
* LinkedIn: [https://www.linkedin.com/in/hiruy-kassa-b17922297/](https://www.linkedin.com/in/hiruy-kassa-b17922297/)
* GitHub: [https://github.com/hiruykassa](https://github.com/hiruykassa)

---
*Last Updated: December 2024*